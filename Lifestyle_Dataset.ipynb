{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a650d6c-bec6-46e0-8638-e52e2a5226c4",
   "metadata": {
    "id": "8a650d6c-bec6-46e0-8638-e52e2a5226c4"
   },
   "source": [
    "# Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba0682-4d9c-45a4-9eb8-4697ae65e9dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "58ba0682-4d9c-45a4-9eb8-4697ae65e9dd",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "8fd0f8e1-6521-4130-b21e-ebc1113f709a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ir_datasets\n",
      "  Downloading ir_datasets-0.5.7-py3-none-any.whl (337 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.9/337.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.12.3)\n",
      "Collecting inscriptis>=2.2.0 (from ir_datasets)\n",
      "  Downloading inscriptis-2.5.0-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.9.4)\n",
      "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (1.25.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets) (4.66.4)\n",
      "Collecting trec-car-tools>=2.5.4 (from ir_datasets)\n",
      "  Downloading trec_car_tools-2.6-py3-none-any.whl (8.4 kB)\n",
      "Collecting lz4>=3.1.10 (from ir_datasets)\n",
      "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting warc3-wet>=0.2.3 (from ir_datasets)\n",
      "  Downloading warc3_wet-0.2.3-py3-none-any.whl (13 kB)\n",
      "Collecting warc3-wet-clueweb09>=0.2.5 (from ir_datasets)\n",
      "  Downloading warc3-wet-clueweb09-0.2.5.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting zlib-state>=0.1.3 (from ir_datasets)\n",
      "  Downloading zlib-state-0.1.6.tar.gz (9.5 kB)\n",
      "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting ijson>=3.1.3 (from ir_datasets)\n",
      "  Downloading ijson-3.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (111 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.8/111.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting unlzw3>=0.2.1 (from ir_datasets)\n",
      "  Downloading unlzw3-0.2.2-py3-none-any.whl (6.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->ir_datasets) (2024.2.2)\n",
      "Collecting cbor>=1.0.0 (from trec-car-tools>=2.5.4->ir_datasets)\n",
      "  Downloading cbor-1.0.0.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: warc3-wet-clueweb09, zlib-state, cbor\n",
      "  Building wheel for warc3-wet-clueweb09 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for warc3-wet-clueweb09: filename=warc3_wet_clueweb09-0.2.5-py3-none-any.whl size=18919 sha256=aeb2219dd9f2cc5fc15d8f18f6e5dc4bc2f2ac1745412fe0458165d5646d469c\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/d7/91/7ffb991df87e62355d945745035470ba2616aa3d83a250b5f9\n",
      "  Building wheel for zlib-state (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for zlib-state: filename=zlib_state-0.1.6-cp310-cp310-linux_x86_64.whl size=21162 sha256=32af94a1e0aab7f6ad500b4b0862fb8930ced646175feb1aa2654918a8a44c97\n",
      "  Stored in directory: /root/.cache/pip/wheels/32/72/7e/aff80f26e926b6e1fb08dfb52aba03c0e058f5e2258deb50a9\n",
      "  Building wheel for cbor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cbor: filename=cbor-1.0.0-cp310-cp310-linux_x86_64.whl size=53429 sha256=41273d7901828f710a24d51f62a6c5874e85406e07457683664b926f97474bf0\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/df/c9/b39e40eccaf76dbd218556639a6dc81562226f4c6a64902c85\n",
      "Successfully built warc3-wet-clueweb09 zlib-state cbor\n",
      "Installing collected packages: warc3-wet-clueweb09, warc3-wet, ijson, cbor, zlib-state, unlzw3, trec-car-tools, lz4, inscriptis, ir_datasets\n",
      "Successfully installed cbor-1.0.0 ijson-3.2.3 inscriptis-2.5.0 ir_datasets-0.5.7 lz4-4.3.3 trec-car-tools-2.6 unlzw3-0.2.2 warc3-wet-0.2.3 warc3-wet-clueweb09-0.2.5 zlib-state-0.1.6\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade ir_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207afbfd-5df9-4f9e-a3df-5ea9f8d997e1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "207afbfd-5df9-4f9e-a3df-5ea9f8d997e1",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "408aead0-3d53-4f0b-c2ac-12dd16350f46",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-terrier\n",
      "  Downloading python-terrier-0.10.1.tar.gz (110 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.25.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from python-terrier) (2.0.3)\n",
      "Collecting wget (from python-terrier)\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from python-terrier) (4.66.4)\n",
      "Collecting pyjnius>=1.4.2 (from python-terrier)\n",
      "  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting matchpy (from python-terrier)\n",
      "  Downloading matchpy-0.5.5-py3-none-any.whl (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting deprecated (from python-terrier)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting chest (from python-terrier)\n",
      "  Downloading chest-0.2.3.tar.gz (9.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.11.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from python-terrier) (2.31.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from python-terrier) (1.4.2)\n",
      "Collecting nptyping==1.4.4 (from python-terrier)\n",
      "  Downloading nptyping-1.4.4-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: more_itertools in /usr/local/lib/python3.10/dist-packages (from python-terrier) (10.1.0)\n",
      "Requirement already satisfied: ir_datasets>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.5.7)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from python-terrier) (3.1.4)\n",
      "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (from python-terrier) (0.14.2)\n",
      "Collecting ir_measures>=0.3.1 (from python-terrier)\n",
      "  Downloading ir_measures-0.3.3.tar.gz (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.8/48.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting dill (from python-terrier)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pytrec_eval_terrier>=0.5.3 (from python-terrier)\n",
      "  Downloading pytrec_eval_terrier-0.5.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typish>=1.7.0 (from nptyping==1.4.4->python-terrier)\n",
      "  Downloading typish-1.9.3-py3-none-any.whl (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.1/45.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (4.12.3)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (4.9.4)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (6.0.1)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (2.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (4.3.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (0.2.3)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (0.1.6)\n",
      "Requirement already satisfied: ijson>=3.1.3 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (3.2.3)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from ir_datasets>=0.3.2->python-terrier) (0.2.2)\n",
      "Collecting cwl-eval>=1.0.10 (from ir_measures>=0.3.1->python-terrier)\n",
      "  Downloading cwl-eval-1.0.12.tar.gz (31 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->python-terrier) (2024.2.2)\n",
      "Collecting heapdict (from chest->python-terrier)\n",
      "  Downloading HeapDict-1.0.1-py3-none-any.whl (3.9 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->python-terrier) (1.14.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->python-terrier) (2.1.5)\n",
      "Collecting multiset<3.0,>=2.0 (from matchpy->python-terrier)\n",
      "  Downloading multiset-2.1.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->python-terrier) (2024.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels->python-terrier) (24.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->ir_datasets>=0.3.2->python-terrier) (2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels->python-terrier) (1.16.0)\n",
      "Requirement already satisfied: cbor>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from trec-car-tools>=2.5.4->ir_datasets>=0.3.2->python-terrier) (1.0.0)\n",
      "Building wheels for collected packages: python-terrier, ir_measures, chest, wget, cwl-eval\n",
      "  Building wheel for python-terrier (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for python-terrier: filename=python_terrier-0.10.1-py3-none-any.whl size=117255 sha256=9e89f44aefc7d4d9b1a464e1fb69d9a41a37a0dc7763de95cab57f14d3405871\n",
      "  Stored in directory: /root/.cache/pip/wheels/58/88/6d/fd8acd9b71f17907235017371cff103c736d40e55101783cc7\n",
      "  Building wheel for ir_measures (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for ir_measures: filename=ir_measures-0.3.3-py3-none-any.whl size=61183 sha256=0c54ba21426247b7a9dd21e65d6d3cfee2901b689a69f1c60516f9f7fc2d29cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/0e/22/718279f23fef1673a4c5e433881c25080a6afaa147e007183e\n",
      "  Building wheel for chest (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for chest: filename=chest-0.2.3-py3-none-any.whl size=7612 sha256=e597d148507f6f9ee8b7795d9756ce8d52ca6d45471203d031a15f80250f299e\n",
      "  Stored in directory: /root/.cache/pip/wheels/88/cf/99/4773b31f855f9ecedc32a0ae400f7a4a3001b37c439b6d1a73\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=a6dcdbd9e2a1a4cd82ec6c1776f3989ab50c13714368af2cde4df8802f0e6d98\n",
      "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "  Building wheel for cwl-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cwl-eval: filename=cwl_eval-1.0.12-py3-none-any.whl size=38068 sha256=38f2c033e7bb113820a6791374fddf724e875208bd45efa7a2cf92749b927800\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/c1/94/94a3e5379b1aa8fb7c7f1ad1956305d5edc98ef745b6067d87\n",
      "Successfully built python-terrier ir_measures chest wget cwl-eval\n",
      "Installing collected packages: wget, typish, pyjnius, multiset, heapdict, pytrec_eval_terrier, nptyping, matchpy, dill, deprecated, cwl-eval, chest, ir_measures, python-terrier\n",
      "Successfully installed chest-0.2.3 cwl-eval-1.0.12 deprecated-1.2.14 dill-0.3.8 heapdict-1.0.1 ir_measures-0.3.3 matchpy-0.5.5 multiset-2.1.1 nptyping-1.4.4 pyjnius-1.6.1 python-terrier-0.10.1 pytrec_eval_terrier-0.5.6 typish-1.9.3 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "#pip install python-terrier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c9a03-9efe-4a2b-80d3-8d302beae5e8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "476c9a03-9efe-4a2b-80d3-8d302beae5e8",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "cf49658d-fbee-41ed-cbbb-bf8037bf7a75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ir-measures in /usr/local/lib/python3.10/dist-packages (0.3.3)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.5 in /usr/local/lib/python3.10/dist-packages (from ir-measures) (0.5.6)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in /usr/local/lib/python3.10/dist-packages (from ir-measures) (1.0.12)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cwl-eval>=1.0.10->ir-measures) (1.25.2)\n"
     ]
    }
   ],
   "source": [
    "#pip install ir-measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3939e9-ae64-49ba-936b-5cdd359f45ab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ef3939e9-ae64-49ba-936b-5cdd359f45ab",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "35d8a7cb-7cae-4ab8-b29e-9fff4d439ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.8.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8GVO8pWi8HEx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "8GVO8pWi8HEx",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "d3aed8b6-de22-415d-de09-8a29233d11c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IOa_4NGV_HqZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "IOa_4NGV_HqZ",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "6af93cac-f8a7-4628-84a2-a192fd755d10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612f676-5686-4d48-b428-53e849318c1c",
   "metadata": {
    "id": "6612f676-5686-4d48-b428-53e849318c1c"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dcf75e0-018b-4efe-acf9-b523c76c5a7a",
   "metadata": {
    "id": "2dcf75e0-018b-4efe-acf9-b523c76c5a7a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ir_datasets\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize , sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "# from spellchecker import SpellChecker\n",
    "from typing import List\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "# import gdown\n",
    "from google.colab import files\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from google.colab import drive\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45504cc6-4ee0-4ea9-9dca-24fcc1eac801",
   "metadata": {
    "id": "45504cc6-4ee0-4ea9-9dca-24fcc1eac801"
   },
   "source": [
    "# Downloads Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd018e4-c741-4e9a-83c8-56f99cf308c7",
   "metadata": {
    "id": "2bd018e4-c741-4e9a-83c8-56f99cf308c7"
   },
   "source": [
    "### Load Recreation Dataset && Understand dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5f0100-c8a4-4c2f-8988-4be4546f0b36",
   "metadata": {
    "id": "5d5f0100-c8a4-4c2f-8988-4be4546f0b36"
   },
   "outputs": [],
   "source": [
    "dataset = ir_datasets.load(\"lotte/lifestyle/dev/forum\")\n",
    "for doc in dataset.docs_iter():\n",
    "    doc # namedtuple<doc_id, text>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36b630bb-d721-4b1a-8cc6-48c80ce1118b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "36b630bb-d721-4b1a-8cc6-48c80ce1118b",
    "outputId": "5780e593-41ff-45b2-f07b-1b272b2cf7de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268893"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.docs_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c331d1-915d-4130-8a03-b990999072cd",
   "metadata": {
    "id": "b0c331d1-915d-4130-8a03-b990999072cd"
   },
   "outputs": [],
   "source": [
    "docs = pd.DataFrame(dataset.docs_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fade8d6-5193-45b2-9bde-204e52228561",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "9fade8d6-5193-45b2-9bde-204e52228561",
    "outputId": "c81088ff-701f-4312-8964-1498f47fb243"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "dataframe",
       "variable_name": "docs"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-2ea8676a-2e03-4e15-a963-503fe39ef1c5\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>In my experience rabbits are very easy to hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>...rabbits can be easily trained to use a litt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>It could be a multitude of things. Lack of exe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I've had a lot of success with crate training....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I've seen on the \"Dog Whisperer\" that dogs can...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ea8676a-2e03-4e15-a963-503fe39ef1c5')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-2ea8676a-2e03-4e15-a963-503fe39ef1c5 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-2ea8676a-2e03-4e15-a963-503fe39ef1c5');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-09fcb150-819b-40d3-bcfc-a1e9ba489813\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-09fcb150-819b-40d3-bcfc-a1e9ba489813')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-09fcb150-819b-40d3-bcfc-a1e9ba489813 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "  doc_id                                               text\n",
       "0      0  In my experience rabbits are very easy to hous...\n",
       "1      1  ...rabbits can be easily trained to use a litt...\n",
       "2      2  It could be a multitude of things. Lack of exe...\n",
       "3      3  I've had a lot of success with crate training....\n",
       "4      4  I've seen on the \"Dog Whisperer\" that dogs can..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d362091-0f18-40a4-a6a3-591b86d1c92a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d362091-0f18-40a4-a6a3-591b86d1c92a",
    "outputId": "7bad50df-d81b-402c-a44c-4140f02af02b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 268893 entries, 0 to 268892\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   doc_id  268893 non-null  object\n",
      " 1   text    268893 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "docs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77bc38bf-f9f2-4832-9e44-8bfc2bbc6e35",
   "metadata": {
    "id": "77bc38bf-f9f2-4832-9e44-8bfc2bbc6e35"
   },
   "outputs": [],
   "source": [
    "queries = pd.DataFrame(dataset.queries_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05560cdd-d0ef-49a4-80f6-d93428d67ee6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05560cdd-d0ef-49a4-80f6-d93428d67ee6",
    "outputId": "4f533825-e563-46cb-960f-acc292f6a9d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2076 entries, 0 to 2075\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   query_id  2076 non-null   object\n",
      " 1   text      2076 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 32.6+ KB\n"
     ]
    }
   ],
   "source": [
    "queries.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4bb07f15-54b7-4666-91ad-5a56c234fc8b",
   "metadata": {
    "id": "4bb07f15-54b7-4666-91ad-5a56c234fc8b"
   },
   "outputs": [],
   "source": [
    "qrels = pd.DataFrame(dataset.qrels_iter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb88a5d4-be04-4e3a-8348-8d69f533769e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb88a5d4-be04-4e3a-8348-8d69f533769e",
    "outputId": "8a133301-1154-4ca9-f924-c9359cdaff5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12823 entries, 0 to 12822\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   query_id   12823 non-null  object\n",
      " 1   doc_id     12823 non-null  object\n",
      " 2   relevance  12823 non-null  int64 \n",
      " 3   iteration  12823 non-null  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 400.8+ KB\n"
     ]
    }
   ],
   "source": [
    "qrels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896d404-a555-47a3-b7a3-5b951257641b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4896d404-a555-47a3-b7a3-5b951257641b",
    "outputId": "83959cd5-dd53-45cd-941b-914db04b5349"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenericDoc(doc_id='0', text=\"In my experience rabbits are very easy to housebreak. They like to pee and poop in the same place every time, so in most cases all you have to do is put a little bit of their waste in the litter box and they will happily use the litter box. It is very important that if they go somewhere else, miss the edge or kick waste out of the box that you clean it up well and immediately as otherwise those spots will become existing places to pee and poop. When you clean the box, save a little bit of waste and put it in the cleaned box so it smells right to them. For a more foolproof method, you can get a piece of wood soaked with their urine and put that in the box along with droppings or cage them so that they are only in their litter box for a week. Generally, if I try the first method and find that they are not using only the box on the first day, I go for the litter box only for a week method. The wood block works well if you are moving from a hutch outdoors to a litter box indoors. If you have an indoor cage, you can use the cage itself as the litter box (or attach a litter box to the section of the cage the rabbit has used for waste.) Be sure to use clay or newsprint litter as the other types aren't necessarily good for rabbits. Wood litter is okay if you are sure it isn't fir. The most important thing is to clean anywhere they have an accident. High sided boxes help with avoiding kicking soiled litter out of the box, which is the biggest cause of failure in my experience.\")\n",
      "GenericDoc(doc_id='1', text='...rabbits can be easily trained to use a litter tray, sometimes with more reliability than your average cat! The natural instinct of a wild rabbit to use one area as its latrine is still apparent in its domestic counterparts. (1) The actual process is very similar to pad training a dog or litter box training a cat. Keep the rabbit confined to a small area while training, move any \"accidents\" to the litter box, and the rabbit will naturally start using that area for its business. The source link has the details. (1) Litter Training Your Rabbit Emma Magnus MSc Association of Pet Behaviour Counsellors apbc.org.uk')\n"
     ]
    }
   ],
   "source": [
    "for doc in dataset.docs_iter()[:2]:\n",
    "  print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b61c60-ba15-4ca8-b675-37529d7b2539",
   "metadata": {
    "id": "67b61c60-ba15-4ca8-b675-37529d7b2539"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "m62UwXHqwD3b",
   "metadata": {
    "id": "m62UwXHqwD3b"
   },
   "outputs": [],
   "source": [
    "class DataPreProcessing:\n",
    "    custom_words = {\n",
    "    'isnt', 'arent', 'im', 'id', 'ie', 'eg', 'ive', 'whatev', 'wed', 'somehow',\n",
    "    'going', 'get', 'yes', 'no', 'couldnt', 'didnt', 'dont', 'doesnt', 'would',\n",
    "    'could', 'should', 'cant', 'wont', 'hasnt', 'hadnt', 'havent', 'mightnt',\n",
    "    'mustnt', 'neednt', 'shall', 'shant', 'werent', 'wouldnt', 'ought', 'oughtnt',\n",
    "    'aint', 'gonna', 'wanna', 'whatcha', 'yall', 'ya', 'gotta', 'coulda', 'shoulda',\n",
    "    'woulda', 'lotta', 'lemme', 'kinda', 'sorta', 'hafta', 'dunno', 'outta', 'alot',\n",
    "    'yup', 'nope', 'nah', 'yeah', 'uh', 'um', 'uhm', 'okay', 'ok', 'yep', 'hmm',\n",
    "    'mmm', 'oh', 'hey', 'hi', 'hello', 'bye', 'goodbye', 'please', 'thanks', 'thank',\n",
    "    'welcome', 'etc', 'alright', 'okay', 'ok', 'gonna', 'gotta', 'wanna', 'kinda',\n",
    "    'sorta', 'lemme', 'coulda', 'shoulda', 'woulda', 'whereby', 'many', 'much', 'want',\n",
    "    'always'\n",
    "    }\n",
    "    stop_words = set(stopwords.words('english')).union(custom_words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_urls(text):\n",
    "        return re.sub(r'http\\S+|www.\\S+', '', text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_non_english_chars(text):\n",
    "        allowed_chars = string.ascii_letters + string.digits + string.punctuation + \" \"\n",
    "        filtered_text = ''.join(char if char in allowed_chars else '' for char in text)\n",
    "        return filtered_text\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_punctuation(tokens):\n",
    "        translator = str.maketrans({char: ' ' if char != '&' else '' for char in string.punctuation})\n",
    "        # Process each token individually\n",
    "        cleaned_tokens = []\n",
    "        for token in tokens:\n",
    "            no_punct = token.translate(translator)\n",
    "            clean_token = re.sub(r'\\s+', ' ', no_punct).strip()\n",
    "            if clean_token:  # Avoid adding empty strings\n",
    "                cleaned_tokens.append(clean_token)\n",
    "        return cleaned_tokens\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_abbreviation(tokens):\n",
    "        new_text = []\n",
    "        for i in tokens:\n",
    "            if i.upper() in DataPreProcessing.abbreviations:\n",
    "                new_text.append(DataPreProcessing.abbreviations[i.upper()])\n",
    "            else:\n",
    "                new_text.append(i)\n",
    "        return new_text\n",
    "\n",
    "    @staticmethod\n",
    "    def toLowercase(text):\n",
    "        return text.lower()\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_repeated_chars(text):\n",
    "        pattern = r'(\\w)(\\1{2,})'\n",
    "        fixed_text = re.sub(pattern, r'\\1\\1', text)\n",
    "        return fixed_text\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_time(text):\n",
    "        time_pattern = r'\\b\\d{1,2}:\\d{2}(?::\\d{2})?\\b'\n",
    "        text_without_time = re.sub(time_pattern, '', text)\n",
    "        clean_text = re.sub(r'\\s+', ' ', text_without_time).strip()\n",
    "        return clean_text\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_null_values(docs):\n",
    "        return docs.dropna()\n",
    "\n",
    "    @staticmethod\n",
    "    def tokenize_text(text):\n",
    "        return word_tokenize(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_stopwords(tokens):\n",
    "        return [word for word in tokens if word not in DataPreProcessing.stop_words]\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_duplicated_chars(tokens):\n",
    "        def has_duplicated_chars(word):\n",
    "            return len(set(word)) == 1\n",
    "\n",
    "        filtered_words = [word for word in tokens if len(word) != 2 and not has_duplicated_chars(word)]\n",
    "        return filtered_words\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_words_start_with_duplicate_chars(text):\n",
    "        # Define a regular expression pattern to match words starting with duplicate alphabetical characters\n",
    "        pattern = r'\\b([a-zA-Z])\\1\\w*\\b'\n",
    "        # Use re.sub to replace matched words with an empty string\n",
    "        result = re.sub(pattern, '', text)\n",
    "        return result\n",
    "\n",
    "    @staticmethod\n",
    "    def get_wordnet_pos(treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "    @staticmethod\n",
    "    def lemmatize_tokens(tokens):\n",
    "        pos_tagged_tokens = pos_tag(tokens)\n",
    "        lemmatized_tokens = [\n",
    "            DataPreProcessing.lemmatizer.lemmatize(token, DataPreProcessing.get_wordnet_pos(pos_tag))\n",
    "            for token, pos_tag in pos_tagged_tokens\n",
    "        ]\n",
    "        return lemmatized_tokens\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        return [DataPreProcessing.stemmer.stem(token) for token in tokens]\n",
    "\n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        text = DataPreProcessing.remove_urls(text)\n",
    "        text = DataPreProcessing.remove_non_english_chars(text)\n",
    "        text = DataPreProcessing.remove_time(text)\n",
    "        text = DataPreProcessing.fix_repeated_chars(text)\n",
    "        text = DataPreProcessing.toLowercase(text)\n",
    "        tokens = DataPreProcessing.tokenize_text(text)\n",
    "        tokens = DataPreProcessing.remove_punctuation(tokens)\n",
    "        tokens = DataPreProcessing.remove_stopwords(tokens)\n",
    "        tokens = DataPreProcessing.stem_tokens(tokens)\n",
    "        return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "S2bx5aWoyUqM",
   "metadata": {
    "id": "S2bx5aWoyUqM"
   },
   "source": [
    "# indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Qac8rh2EyZfj",
   "metadata": {
    "id": "Qac8rh2EyZfj"
   },
   "outputs": [],
   "source": [
    "def custom_tokenizer(text):\n",
    "    return word_tokenize(text)\n",
    "documents = docs['text']\n",
    "tfidf_vectorizer = TfidfVectorizer(preprocessor=DataPreProcessing.process_text , max_features=30000)\n",
    "tfidf_docs = tfidf_vectorizer.fit_transform(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sGfiHlmObnMQ",
   "metadata": {
    "id": "sGfiHlmObnMQ"
   },
   "source": [
    "## Save The Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iwJ5t8C--YkG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwJ5t8C--YkG",
    "outputId": "b43fc8e6-0a22-4d2d-ab39-d5de51fb6bc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')\n",
    "with open('/content/drive/MyDrive/index.pkl', 'wb') as f:\n",
    "    pickle.dump(tfidf_docs, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IDrOuVtWB9WP",
   "metadata": {
    "id": "IDrOuVtWB9WP"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/index2.pkl', 'wb') as g:\n",
    "    pickle.dump(tfidf_vectorizer, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfT9EmUc-iuk",
   "metadata": {
    "id": "dfT9EmUc-iuk"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/index.pkl', 'rb') as f:\n",
    "    tf_idf_docs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "jygVOWByCulO",
   "metadata": {
    "id": "jygVOWByCulO"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/index2.pkl', 'rb') as g:\n",
    "    vectorizer = pickle.load(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnDHi3TRcZPg",
   "metadata": {
    "id": "qnDHi3TRcZPg"
   },
   "source": [
    "## Query Matching and Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DDpPt73-cyyw",
   "metadata": {
    "id": "DDpPt73-cyyw"
   },
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "MF6fDMd0K3_C",
   "metadata": {
    "collapsed": true,
    "id": "MF6fDMd0K3_C",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tfidf_queries = vectorizer.transform(queries['text'])\n",
    "similarity_tfidf = cosine_similarity(tfidf_queries,tf_idf_docs)\n",
    "df_similarity = pd.DataFrame(similarity_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0q3EERveTHt",
   "metadata": {
    "id": "f0q3EERveTHt"
   },
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "tuYynSmvy3wD",
   "metadata": {
    "id": "tuYynSmvy3wD"
   },
   "outputs": [],
   "source": [
    "# Function to get the top 15 similarities for each query\n",
    "def get_top_n_similarities(siml_df, n=10):\n",
    "    top_n_df = pd.DataFrame()\n",
    "    for query_index in siml_df.index:\n",
    "        top_n_similarities = siml_df.loc[query_index].nlargest(n)\n",
    "        top_n_df_query = pd.DataFrame({\n",
    "            'query_id': query_index,\n",
    "            'doc_id': top_n_similarities.index,\n",
    "            'similarity': top_n_similarities.values\n",
    "        })\n",
    "        top_n_df = pd.concat([top_n_df, top_n_df_query], ignore_index=True)\n",
    "    return top_n_df\n",
    "\n",
    "top_10_similarities = get_top_n_similarities(df_similarity, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9hDNvBnvemwr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "9hDNvBnvemwr",
    "outputId": "1832cd9b-3b6d-4911-f881-9e2b00367574"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"top_10_similarities\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"query_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"doc_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13030,\n        \"min\": 690,\n        \"max\": 47071,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          7085\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"similarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03168770517276284,\n        \"min\": 0.37196195722468245,\n        \"max\": 0.44966903078303316,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.37550188529866535\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-04be7cec-67b0-4458-b840-403b54706cff\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>doc_id</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>690</td>\n",
       "      <td>0.449669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>9029</td>\n",
       "      <td>0.448264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>47071</td>\n",
       "      <td>0.444758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8512</td>\n",
       "      <td>0.404694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3475</td>\n",
       "      <td>0.387427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>9256</td>\n",
       "      <td>0.386439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>8712</td>\n",
       "      <td>0.385842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>7752</td>\n",
       "      <td>0.379872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>7085</td>\n",
       "      <td>0.375502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>6510</td>\n",
       "      <td>0.371962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04be7cec-67b0-4458-b840-403b54706cff')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-04be7cec-67b0-4458-b840-403b54706cff button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-04be7cec-67b0-4458-b840-403b54706cff');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-ff790763-ab97-403d-a803-1ed0f12872d9\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff790763-ab97-403d-a803-1ed0f12872d9')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-ff790763-ab97-403d-a803-1ed0f12872d9 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   query_id  doc_id  similarity\n",
       "0         0     690    0.449669\n",
       "1         0    9029    0.448264\n",
       "2         0   47071    0.444758\n",
       "3         0    8512    0.404694\n",
       "4         0    3475    0.387427\n",
       "5         0    9256    0.386439\n",
       "6         0    8712    0.385842\n",
       "7         0    7752    0.379872\n",
       "8         0    7085    0.375502\n",
       "9         0    6510    0.371962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_similarities.iloc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aWrBkVlhedd5",
   "metadata": {
    "id": "aWrBkVlhedd5"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "uQetPyu0y8aD",
   "metadata": {
    "id": "uQetPyu0y8aD"
   },
   "outputs": [],
   "source": [
    "def precision_recall_at_10(relevant_docs, retrieved_docs):\n",
    "    k = 10\n",
    "    # Ensure we do not exceed the length of the retrieved_docs list\n",
    "    retrieved_k = retrieved_docs[:k]\n",
    "    # Calculate the number of relevant and retrieved documents\n",
    "    relevant_and_retrieved = len(set(retrieved_k) & set(relevant_docs))\n",
    "    # Precision: proportion of retrieved documents that are relevant\n",
    "    precision = relevant_and_retrieved / k\n",
    "    # Recall: proportion of relevant documents that are retrieved\n",
    "    recall = relevant_and_retrieved / len(relevant_docs)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "W2wt-weWy_aM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "W2wt-weWy_aM",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "5bf3b036-9085-4a66-b202-aac6b8029faa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query ID: 0\n",
      "Retrieved Docs: [690, 9029, 47071, 8512, 3475, 9256, 8712, 7752, 7085, 6510]\n",
      "Relevant Docs: [116]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 1\n",
      "Retrieved Docs: [8262, 807, 46681, 4110, 51361, 9573, 54893, 39967, 5877, 3252]\n",
      "Relevant Docs: [32, 498, 1142, 3765, 4664, 6030, 7325, 7395, 9573]\n",
      "Precision at 10: 0.1\n",
      "Recall at 10: 0.1111111111111111\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 2\n",
      "Retrieved Docs: [8590, 40048, 7212, 48636, 48492, 50549, 4265, 48284, 2524, 7236]\n",
      "Relevant Docs: [7204, 7205, 7206, 7207, 7210, 7212, 7213, 7214, 7215, 7217, 7225, 7226, 7228, 7229, 7231, 7232, 7236, 7239]\n",
      "Precision at 10: 0.2\n",
      "Recall at 10: 0.1111111111111111\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 3\n",
      "Retrieved Docs: [9432, 1401, 9425, 7329, 2881, 9431, 428, 163512, 5910, 1149]\n",
      "Relevant Docs: [427]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 4\n",
      "Retrieved Docs: [7342, 5557, 2035, 4986, 5934, 9671, 4075, 5803, 7476, 6553]\n",
      "Relevant Docs: [6106, 6107, 6116, 6119, 6121, 6135]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 5\n",
      "Retrieved Docs: [4981, 8853, 7665, 9273, 6, 7184, 5776, 2564, 9534, 3578]\n",
      "Relevant Docs: [6, 5221, 6320, 9273]\n",
      "Precision at 10: 0.2\n",
      "Recall at 10: 0.5\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 6\n",
      "Retrieved Docs: [470, 481, 65115, 9958, 2218, 14287, 471, 52839, 251222, 43323]\n",
      "Relevant Docs: [470, 471, 481, 2218]\n",
      "Precision at 10: 0.4\n",
      "Recall at 10: 1.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 7\n",
      "Retrieved Docs: [9898, 5601, 4503, 9414, 5007, 6107, 8980, 9256, 9641, 7982]\n",
      "Relevant Docs: [6216, 6217, 6219, 6220, 6227, 6228, 6231, 6236, 6238, 6246]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 8\n",
      "Retrieved Docs: [28, 6623, 8600, 54754, 9884, 897, 901, 6951, 2671, 287]\n",
      "Relevant Docs: [2, 28, 6623, 7532]\n",
      "Precision at 10: 0.2\n",
      "Recall at 10: 0.5\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 9\n",
      "Retrieved Docs: [1943, 9558, 6662, 7349, 7181, 9087, 3051, 7512, 4952, 8962]\n",
      "Relevant Docs: [7486, 7487, 7488, 7493, 7494, 7500, 7512, 7514]\n",
      "Precision at 10: 0.1\n",
      "Recall at 10: 0.125\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 10\n",
      "Retrieved Docs: [9432, 7329, 1401, 9425, 9431, 2881, 428, 7761, 5910, 1149]\n",
      "Relevant Docs: [9425, 9430, 9431, 9432]\n",
      "Precision at 10: 0.3\n",
      "Recall at 10: 0.75\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 11\n",
      "Retrieved Docs: [53153, 9029, 9256, 7085, 8067, 9131, 7982, 6787, 8507, 8984]\n",
      "Relevant Docs: [10003, 10005, 10007, 10009, 10013, 10015]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 12\n",
      "Retrieved Docs: [9499, 6409, 1600, 1134, 8299, 8419, 9441, 247834, 9852, 8507]\n",
      "Relevant Docs: [1099, 1104, 1134, 1600]\n",
      "Precision at 10: 0.2\n",
      "Recall at 10: 0.5\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 13\n",
      "Retrieved Docs: [438, 6365, 2226, 349, 15749, 5138, 5136, 5845, 17095, 366]\n",
      "Relevant Docs: [349, 350, 355, 366, 438, 511]\n",
      "Precision at 10: 0.3\n",
      "Recall at 10: 0.5\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 14\n",
      "Retrieved Docs: [210943, 895, 2955, 2465, 3042, 6422, 5637, 7219, 7301, 1749]\n",
      "Relevant Docs: [287]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 15\n",
      "Retrieved Docs: [7527, 8339, 3313, 9029, 8216, 9256, 8981, 7085, 5539, 6294]\n",
      "Relevant Docs: [7435, 7440, 7442, 7449, 7452, 7482]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 16\n",
      "Retrieved Docs: [7664, 3795, 2907, 4594, 7733, 4598, 3023, 8017, 980, 2256]\n",
      "Relevant Docs: [31, 3023]\n",
      "Precision at 10: 0.1\n",
      "Recall at 10: 0.5\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 17\n",
      "Retrieved Docs: [4411, 65207, 2999, 2362, 2315, 2373, 9942, 2735, 10008, 8387]\n",
      "Relevant Docs: [6449, 6451, 6452, 6453, 6457, 6459, 6461]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 18\n",
      "Retrieved Docs: [2315, 2735, 3568, 287, 901, 1217, 10031, 8038, 7790, 781]\n",
      "Relevant Docs: [6945, 6946, 6948, 6949, 6951, 6953, 6954, 6955]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n",
      "Query ID: 19\n",
      "Retrieved Docs: [6670, 3502, 6174, 6662, 8620, 5542, 8476, 2941, 6111, 1619]\n",
      "Relevant Docs: [6707, 6708, 6709]\n",
      "Precision at 10: 0.0\n",
      "Recall at 10: 0.0\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Ensure the data types of query_id columns are consistent\n",
    "top_10_similarities['query_id'] = top_10_similarities['query_id'].astype(int)\n",
    "qrels['query_id'] = qrels['query_id'].astype(int)\n",
    "# Ensure the data types of doc_id columns are consistent\n",
    "top_10_similarities['doc_id'] = top_10_similarities['doc_id'].astype(int)\n",
    "qrels['doc_id'] = qrels['doc_id'].astype(int)\n",
    "\n",
    "query_ids = top_10_similarities['query_id'].unique()\n",
    "\n",
    "# Iterate over each query_id and calculate precision and recall at 10\n",
    "for query_id in query_ids:\n",
    "    # Get the top 10 retrieved docs for this query\n",
    "    retrieved_docs = top_10_similarities[top_10_similarities['query_id'] == query_id]['doc_id'].tolist()\n",
    "\n",
    "    # Get the relevant docs for this query\n",
    "    relevant_docs = qrels[(qrels['query_id'] == query_id) & (qrels['relevance'] == 1)]['doc_id'].tolist()\n",
    "\n",
    "    # Debugging: Print the retrieved_docs and relevant_docs lists to ensure they are correct\n",
    "    if(query_id < 20):\n",
    "      print(f\"Query ID: {query_id}\")\n",
    "      print(f\"Retrieved Docs: {retrieved_docs}\")\n",
    "      print(f\"Relevant Docs: {relevant_docs}\")\n",
    "\n",
    "    # Check if relevant_docs is empty\n",
    "    if not relevant_docs:\n",
    "        print(f\"No relevant documents found for query_id {query_id}\")\n",
    "        continue\n",
    "\n",
    "    # Calculate precision and recall at 10\n",
    "    precision, recall = precision_recall_at_10(relevant_docs, retrieved_docs)\n",
    "\n",
    "    # Print the results\n",
    "    if(query_id < 20):\n",
    "      print(f\"Precision at 10: {precision}\")\n",
    "      print(f\"Recall at 10: {recall}\")\n",
    "      print(\"--------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9Kanr8q51JEG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Kanr8q51JEG",
    "outputId": "afc5090f-c1ca-48ea-b555-c9dfbc8b1551"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2076\n",
      "MAP@10 = 0.09\n"
     ]
    }
   ],
   "source": [
    "def calculate_map_at_k(top_10_similarities: pd.DataFrame, qrels: pd.DataFrame, k: int = 10) -> float:\n",
    "    # Ensure correct data types\n",
    "    top_10_similarities = top_10_similarities.astype({\"query_id\": int, \"doc_id\": int, \"similarity\": float})\n",
    "    qrels = qrels.astype({\"query_id\": int, \"doc_id\": int, \"relevance\": int})\n",
    "\n",
    "    # Parse qrels to create a dictionary of relevant documents for each query\n",
    "    qrels_dict = {}\n",
    "    for entry in qrels.itertuples(index=False):\n",
    "        query_id = entry.query_id\n",
    "        doc_id = entry.doc_id\n",
    "        if query_id not in qrels_dict:\n",
    "            qrels_dict[query_id] = []\n",
    "        qrels_dict[query_id].append(doc_id)\n",
    "\n",
    "    # Parse top_similarity to create a list of predicted documents for each query\n",
    "    predicted_dict = {}\n",
    "    for entry in top_10_similarities.itertuples(index=False):\n",
    "\n",
    "        query_id = entry.query_id\n",
    "        doc_id = entry.doc_id\n",
    "        if query_id not in predicted_dict:\n",
    "            predicted_dict[query_id] = []\n",
    "        predicted_dict[query_id].append(doc_id)\n",
    "\n",
    "    # Initialize variables\n",
    "    Q = len(qrels_dict)  # number of queries\n",
    "    ap = []\n",
    "\n",
    "    # Calculate AP for each query\n",
    "    for q in qrels_dict:\n",
    "        actual = qrels_dict[q]\n",
    "        predicted = predicted_dict.get(q, [])\n",
    "        ap_num = 0\n",
    "        rel_count = 0\n",
    "\n",
    "        for x in range(min(k, len(predicted))):\n",
    "            if predicted[x] in actual:\n",
    "                rel_count += 1\n",
    "                precision_at_k = rel_count / (x + 1)\n",
    "                ap_num += precision_at_k\n",
    "\n",
    "        if len(actual) > 0:\n",
    "            ap_q = ap_num / len(actual)\n",
    "            ap.append(ap_q)\n",
    "\n",
    "    # Calculate MAP\n",
    "    print(len(ap))\n",
    "    map_at_k = sum(ap) / Q\n",
    "    return round(map_at_k, 2)\n",
    "\n",
    "# Example usage:\n",
    "k = 10\n",
    "map_at_k = calculate_map_at_k(top_10_similarities, qrels, k = 10)\n",
    "print(f\"MAP@{k} = {map_at_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "McJqwOXXxPwb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "McJqwOXXxPwb",
    "outputId": "429dfa43-8ae4-40f6-8810-1cf7faddc0e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR = 0.25\n"
     ]
    }
   ],
   "source": [
    "def calculate_mrr(qrels: pd.DataFrame, predicted_dict: dict) -> float:\n",
    "    # Ensure correct data types\n",
    "    qrels = qrels.astype({\"query_id\": int, \"doc_id\": int, \"relevance\": int})\n",
    "\n",
    "    # Parse qrels to create a dictionary of relevant documents for each query\n",
    "    qrels_dict = {}\n",
    "    for entry in qrels.itertuples(index=False):\n",
    "        query_id = entry.query_id\n",
    "        doc_id = entry.doc_id\n",
    "        if query_id not in qrels_dict:\n",
    "            qrels_dict[query_id] = []\n",
    "        qrels_dict[query_id].append(doc_id)\n",
    "\n",
    "    # Initialize variables\n",
    "    Q = len(qrels_dict)  # number of queries\n",
    "    cumulative_reciprocal = 0\n",
    "\n",
    "    # Calculate the reciprocal of the first actual relevant rank for each query\n",
    "    for query_id, actual_docs in qrels_dict.items():\n",
    "        if query_id in predicted_dict:\n",
    "            predicted_docs = predicted_dict[query_id]\n",
    "            for rank, doc_id in enumerate(predicted_docs, start=1):\n",
    "                if doc_id in actual_docs:\n",
    "                    cumulative_reciprocal += 1 / rank\n",
    "                    break\n",
    "\n",
    "    # Calculate MRR\n",
    "    mrr = cumulative_reciprocal / Q\n",
    "\n",
    "    # Generate results\n",
    "    return round(mrr, 2)\n",
    "\n",
    "# Generate predicted_dict from top_10_similarities for MRR calculation\n",
    "predicted_dict = {}\n",
    "for entry in top_10_similarities.itertuples(index=False):\n",
    "    query_id = entry.query_id\n",
    "    doc_id = entry.doc_id\n",
    "    if query_id not in predicted_dict:\n",
    "        predicted_dict[query_id] = []\n",
    "    predicted_dict[query_id].append(doc_id)\n",
    "\n",
    "# Calculate MRR\n",
    "mrr = calculate_mrr(qrels, predicted_dict)\n",
    "print(f\"MRR = {mrr}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "8a650d6c-bec6-46e0-8638-e52e2a5226c4",
    "6612f676-5686-4d48-b428-53e849318c1c",
    "45504cc6-4ee0-4ea9-9dca-24fcc1eac801",
    "67b61c60-ba15-4ca8-b675-37529d7b2539",
    "sGfiHlmObnMQ"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
